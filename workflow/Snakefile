from Cython.Build import cythonize
import pandas as pd
import numpy as np

configfile: "workflow/config/config.yml"

wildcard_constraints:
    run=r"\d+",
    runs=r"\d+",

rule all: 
    input:
        "results/__cythonized__",

        "results/synthetic/er/n=10 p=0.5 r=0.5 d=False/cx/e=True p=False l=10 s=1/cx_2_combined.csv",
        "results/synthetic/er/n=10 p=0.5 r=0.5 d=True/cx/e=True p=False l=10 s=1/cx_2_combined.csv",
        "results/synthetic/er/n=10 p=0.5 r=0.5 d=False/cx/e=False p=False l=10 s=20/cx_2_combined.csv",
        "results/synthetic/er/n=10 p=0.5 r=0.5 d=True/cx/e=False p=False l=10 s=20/cx_2_combined.csv", 
        
        "results/synthetic/complete/n=20 r=0.5 d=False/cx/e=False p=False l=10 s=20/cx_2_combined.csv",
        "results/synthetic/complete/n=20 r=0.5 d=False/pyr/s=1000 sp=1/pyr_2_combined.csv",
        
        "results/synthetic/random/n=20 m=50 r=0.5 d=False/cx/e=False p=False l=10 s=20/cx_0_combined.csv",
        "results/synthetic/random/n=20 m=50 r=0.5 d=False/pyr/s=1000 sp=1/pyr_3_combined.csv", 

        "results/synthetic/random/n=20 m=50 r=0.5 d=False/pyr/s=1000 sp=1/pyr_10_combined.csv",  

        "results/synthetic/random/n=20 m=50 r=0.5 d=False/pyr/s=1000 sp=1/pyr_10_combined.csv", 

        expand("results/synthetic/sbm/exp={exp} r=0.5 d=False/pyr/s=1000 sp=None/pyr_10_combined.csv", exp=range(0, len(config['sbm-exps']))),

        expand("results/synthetic/sbm/exp={exp} r=0.5 d=False/cx/e=False p=False l=10 s=20/cx_10_combined.csv", exp=range(0, len(config['sbm-exps']))),

rule time_exp:
    input:
        expand("results/synthetic/complete/n={n} r=0.5 d=False/cx/e=True p=False l=10 s=1/cx_0_combined.csv", n=range(25, 31, 1))
        #expand("results/synthetic/complete/n={n} r=0.5 d=False/cx/e=False p=False l=10 s=20/cx_0_combined.csv", n=range(10, 1000, 5))

rule cythonize:
    # Cythonizes the required files.
    input:
        "src/py_raccoon/balance_sampling.pyx",
        "src/py_raccoon/balance_spanning_trees.pyx"
    output:
        # actual output filename sytem-dependent and not relevant -> __cythonized__ used to mark dependencies and detect changes by snakemake.
        "results/__cythonized__"
    shell:
        # remove option '-a' if you don't need to debug / profile
        "C_INCLUDE_PATH=$(python -c 'import numpy; print(numpy.get_include())') cythonize -i -a {input} && touch {output}"
       
rule random_pyr:
    input:
        "results/__cythonized__"
    output:
        "results/synthetic/random/n={n_nodes} m={n_edges} r={neg_edge_prob} d=False/pyr/s={n_samples} sp={pyr_spec_edge_prob}/run/pyr_{run}.csv"
    params:
        kind = "random",
        alg = "pyr",
    script:
        "scripts/experiment.py"

rule random_cx:
    output:
        "results/synthetic/random/n={n_nodes} m={n_edges} r={neg_edge_prob} d={directed}/cx/e={exact} p={parallel} l={max_length} s={n_samples}/run/cx_{run}.csv"
    params:
        kind = "random",
        alg="cx",
    script:
        "scripts/experiment.py"

rule complete_pyr:
    input:
        "results/__cythonized__"
    output:
        "results/synthetic/complete/n={n_nodes} r={neg_edge_prob} d=False/pyr/s={n_samples} sp={pyr_spec_edge_prob}/run/pyr_{run}.csv"
    params:
        kind = "complete",
        alg = "pyr",
    script:
        "scripts/experiment.py"

rule complete_cx:
    output:
        "results/synthetic/complete/n={n_nodes} r={neg_edge_prob} d={directed}/cx/e={exact} p={parallel} l={max_length} s={n_samples}/run/cx_{run}.csv"
    params:
        kind = "complete",
        alg="cx",
    script:
        "scripts/experiment.py"

rule er_pyr:
    input:
        "results/__cythonized__"
    output:
        "results/synthetic/er/n{n_nodes} p={prob_p} r={neg_edge_prob} d=False/pyr/s={n_samples} sp={pyr_spec_edge_prob}/run/pyr_{run}.csv"
    params:
        kind = "er",
        alg = "pyr"
    script:
        "scripts/experiment.py"

rule er_cx:
    output:
        "results/synthetic/er/n={n_nodes} p={prob_p} r={neg_edge_prob} d={directed}/cx/e={exact} p={parallel} l={max_length} s={n_samples}/run/cx_{run}.csv"
    params:
        kind = "er",
        alg="cx",
    script:
        "scripts/experiment.py"
    
rule sbm_pyr:
    input:
        "results/__cythonized__"
    output:
        "results/synthetic/sbm/exp={exp} r={neg_edge_prob} d=False/pyr/s={n_samples} sp={pyr_spec_edge_prob}/run/pyr_{run}.csv"
    params:
        kind = "sbm",
        alg = "pyr",
        com_sizes = lambda wildcards: config['sbm-exps'][int(wildcards.exp)]['sizes'],
        edge_probs = lambda wildcards: config['sbm-exps'][int(wildcards.exp)]['p'],
    script:
        "scripts/experiment.py"

rule sbm_cx:
    output:
        "results/synthetic/sbm/exp={exp} r={neg_edge_prob} d={directed}/cx/e={exact} p={parallel} l={max_length} s={n_samples}/run/cx_{run}.csv"
    params:
        kind = "sbm",
        alg="cx",
        com_sizes = lambda wildcards: config['sbm-exps'][int(wildcards.exp)]['sizes'],
        edge_probs = lambda wildcards: config['sbm-exps'][int(wildcards.exp)]['p'],
    script:
        "scripts/experiment.py"



rule combine_exps:
    input: 
        lambda wildcards: expand("{{path}}/run/{{alg}}_{run}.csv", run=list(range(0, int(wildcards.runs) + 1))),
    output: 
        "{path}/{alg}_{runs}_combined.csv",
    run:
        df_data = pd.concat([pd.read_csv(file) for file in input])
        df_data.to_csv(output[0])